<!DOCTYPE html>
<html lang='en'><head>
  <meta charset='utf-8'>
<meta name='viewport' content='width=device-width, initial-scale=1'>
<meta name='description' content='The first thing whenever one starts learning about Machine Learning algorithms is Linear Regression. But the way people generally blaze through it because it&rsquo;s rudimentary and label it as very intuitive doesn&rsquo;t sit well with me.
So, in this article we will build a Linear Regression model with the help of probability.
Regression&rsquo;s idea is to determine the strength of relation between a bunch of independent variables $x = (x_1, x_2, &hellip; x_n)$ and a dependent variable $y$ (i.'>
<meta name='theme-color' content='#b22222'>

<meta property='og:title' content='LMS • tTales'>
<meta property='og:description' content='The first thing whenever one starts learning about Machine Learning algorithms is Linear Regression. But the way people generally blaze through it because it&rsquo;s rudimentary and label it as very intuitive doesn&rsquo;t sit well with me.
So, in this article we will build a Linear Regression model with the help of probability.
Regression&rsquo;s idea is to determine the strength of relation between a bunch of independent variables $x = (x_1, x_2, &hellip; x_n)$ and a dependent variable $y$ (i.'>
<meta property='og:url' content='https://011ivand3r.github.io/tTales/posts/lms/'>
<meta property='og:site_name' content='tTales'>
<meta property='og:type' content='article'><meta property='og:image' content='https://011ivand3r.github.io/tTales/imgs/dice.jpg'><meta property='article:section' content='posts'><meta property='article:tag' content='Machine Learning'><meta property='article:tag' content='Probability'><meta property='article:tag' content='Regression'><meta property='article:published_time' content='2020-07-25T13:39:03&#43;05:30'/><meta property='article:modified_time' content='2020-07-25T13:39:03&#43;05:30'/><meta name='twitter:card' content='summary_large_image'><meta property='twitter:image' content='https://011ivand3r.github.io/tTales/imgs/dice.jpg'>

<meta name="generator" content="Hugo 0.69.0" />

  <title>LMS • tTales</title>
  <link rel='canonical' href='https://011ivand3r.github.io/tTales/posts/lms/'>
  
  
  <link rel='icon' href='/tTales/favicon.ico'>
<link rel='stylesheet' href='/tTales/assets/css/main.ab98e12b.css'><link rel='stylesheet' href='/tTales/css/custom.css'><style>
:root{--color-accent:#b22222;}
</style>

  

</head>
<body class='page type-posts has-cover has-sidebar'>

  <div class='site'><div id='sidebar' class='sidebar'>
  <a class='screen-reader-text' href='#main-menu'>Skip to Main Menu</a>

  <div class='container'><section class='widget widget-about sep-after'>
  <header>
    
    <div class='logo'>
      <a href='/tTales/'>
        <img src='/tTales/imgs/logo_min_black.png'>
      </a>
    </div>
    
    <h2 class='title site-title '>
      <a href='/tTales/'>
       
      </a>
    </h2>
    <div class='desc'>
    
    </div>
  </header>

</section>
<section class='widget widget-search sep-after'>
  <header>
    <h4 class='title widget-title'>Search</h4>
  </header>

  <form action='/tTales/search' id='search-form' class='search-form'>
    <label>
      <span class='screen-reader-text'>Search</span>
      <input id='search-term' class='search-term' type='search' name='q' placeholder='Search&hellip;'>
    </label></form>

</section>
</div>

  <div class='sidebar-overlay'></div>
</div><div class='main'><nav id='main-menu' class='menu main-menu' aria-label='Main Menu'>
  <div class='container'>
    <a class='screen-reader-text' href='#content'>Skip to Content</a>

<button id='sidebar-toggler' class='sidebar-toggler' aria-controls='sidebar'>
  <span class='screen-reader-text'>Toggle Sidebar</span>
  <span class='open'><svg class='icon' viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
  
  <line x1="3" y1="12" x2="21" y2="12" />
  <line x1="3" y1="6" x2="21" y2="6" />
  <line x1="3" y1="18" x2="21" y2="18" />
  
</svg>
</span>
  <span class='close'><svg class='icon' viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
  
  <line x1="18" y1="6" x2="6" y2="18" />
  <line x1="6" y1="6" x2="18" y2="18" />
  
</svg>
</span>
</button>
    <ul><li class='item'>
        <a href='/tTales/'>Latest</a>
      </li><li class='item'>
        <a href='/tTales/posts/'>Posts</a>
      </li><li class='item'>
        <a href='/tTales/about/'>About</a>
      </li></ul>
  </div>
</nav><div class='header-widgets'>
        <div class='container'></div>
      </div>

      <header id='header' class='header site-header'>
        <div class='container sep-after'>
          <div class='header-info'><p class='site-title title'>tTales</p><p class='desc site-desc'>Overthought thoughts</p>
          </div>
        </div>
      </header>

      <main id='content'>


<article lang='en' class='entry'>
  <header class='header entry-header'>
  <div class='container sep-after'>
    <div class='header-info'>
      <h1 class='title'>LMS</h1>
      

    </div>
    <div class='entry-meta'>
  <span class='posted-on'><svg class='icon' viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
  
  <rect x="3" y="4" width="18" height="18" rx="2" ry="2"/>
  <line x1="16" y1="2" x2="16" y2="6"/>
  <line x1="8" y1="2" x2="8" y2="6"/>
  <line x1="3" y1="10" x2="21" y2="10"/>
  
</svg>
<span class='screen-reader-text'>Posted on </span>
  <time class='entry-date' datetime='2020-07-25T13:39:03&#43;05:30'>2020, Jul 25</time>
</span>

  
  
<span class='reading-time'><svg class='icon' viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
  
  <circle cx="12" cy="12" r="10"/>
  <polyline points="12 6 12 12 15 15"/>
  
</svg>
4 mins read
</span>


</div>


  </div>
</header>

  <div class='entry-cover'>
  <figure class='container cover-wide'>
    <img src='/tTales/imgs/dice.jpg'/>
    
      
    
  </figure>
</div>
  

  <div class='container entry-content'>
  <p>The first thing whenever one starts learning about Machine Learning algorithms is Linear Regression. But the way people generally blaze through it because it&rsquo;s <em>rudimentary</em> and label it as <em>very intuitive</em> doesn&rsquo;t sit well with me.</p>
<p>So, in this article we will build a Linear Regression model with the help of probability.</p>
<p><strong>Regression&rsquo;s</strong> idea is to determine the strength of relation between a bunch of independent variables $x = (x_1, x_2, &hellip; x_n)$ and a dependent variable $y$ (i.e. target variable).</p>
<p>So, generally the Linear Regression hypothesis is represented as &ndash;
$$ h_{\theta} = \theta_0 + \theta_1x_1 + \theta_2x_2 + &hellip; + \theta_nx_n $$
$$ \therefore h_{\theta} = \sum_{i=1}^{n} \theta_ix_i $$
And in vector form we can write the same as &ndash;
$$ y = h(x) = \theta^Tx  $$
Note: $h_\theta(x)$ is same as $h(x)$</p>
<p>In a Machine Learning problem, we can have different kinds of errors. For example, we can have errors if we don&rsquo;t consider some feature(s) to determine the result, although it is very relevant to the problem. It can also be a measurement error, or a random noise. So, the target variable can be written as &ndash;
$$ y^{(i)} = \theta^Tx^{(i)} + \epsilon^{(i)} $$</p>
<p>$\epsilon^{(i)}$ accounting for the errors in our model. We assume that the error term of each training example, $\epsilon^{(i)}$ is Independently and Identically Distributed (IID). And they satisfy a Normal Distribution with mean 0, and standard deviation $\sigma$.</p>
<p>And now you might ask <em>why Normal(Gaussian) Distribution? Why not anything else?</em></p>
<p>The answer is given by <a href="https://www.youtube.com/watch?v=YAlJCEDH2uY"><strong>Central Limit Theorem</strong></a>. Which tells us that if you take sufficiently large number of random numbers, then the sum of the numbers will be approximately normally distributed. So, this means that the error of one training example has the same distribution as the error of other training examples.</p>
<p>Also, $y^{(i)}$ is a random variable that satisfies Normal distribution with the mean $\theta^Tx$ and variance being $\sigma^2$. Now if we write the probability distribution of the predicted values $y$, given $X$ and the parameter $\theta$. It is given as follows:
$$p(y^{(i)}|x^{(i)}; \theta) = \frac{1}{\sqrt2\pi\sigma}exp(-\frac{(y^{(i)}- \theta^Tx^{(i)})^2}{2\sigma^2})$$
This means that the distribution of $y^{(i)}$ given $x^{(i)}$ is parameterized by $\theta$.</p>
<p>Now here is where, we get introduced directly to the <strong>Ordinary Least Squares</strong>, and we try to find the most likely $\theta$ for a given set of $(y^i, x^i)$ pairs by reducing the cost function. But, a more insightful way to find this estimate is to maximize the <a href="https://en.wikipedia.org/wiki/Likelihood_function"><strong>likelihood function</strong></a>.</p>
<p><em>So, what is <strong>Likelihood function?</strong></em></p>
<p>It is kind of a negative of loss function. But, fundamentally speaking it is the probability distribution function of $\theta$.</p>
<p><img src="/tTales/imgs/Likelihood.png" alt=""></p>
<p>The picture above taken from <a href="https://www.youtube.com/channel/UCtYLUTtgS3k1Fg4y5tAhLbw">Statquest wit Josh Stammer&rsquo;s</a> YouTube channel give the easiest idea of what Likelihood is about. You can check out his <a href="https://www.youtube.com/watch?v=pYxNSUDSFH4">video</a> for more details.</p>
<p>Since we assume that every training example is IID, we can write for n training examples &ndash;</p>
<p>$$L(\theta) = \prod_{i=1}^{n} p(y^{(i)}|x^{(i)}; \theta)$$
$$\implies L(\theta) = \prod_{i=1}^{n} \frac{1}{\sqrt2\pi\sigma}exp(-\frac{(y^{(i)}- \theta^Tx^{(i)})^2}{2\sigma^2})$$</p>
<p>We need to maximize this function in order to find the parameter values that give the distribution that maximizes the probability of observing the data. The parameter values(i.e. $\theta$) are found such that they maximize the likelihood that the process described by the model produce the data that were actually observed.</p>
<p>To find this function&rsquo;s maximum is quite tough, so we can find the maximum of the $\log$ of the Likelihood function. This is only possible because the Likelihood function and the log of the Likelihood function both peak at the same point for the same $\mu$ and $\sigma$. Also, it&rsquo;s way, way easier to find the derivative.</p>
<p>So, let&rsquo;s find the derivative.</p>
<p>\begin{align*}
$$ L(\mu|y)} &amp;= afdsaf \<br>
&amp;= btcvgrw\<br>
&amp;= sfsfasdff$$
\end{align*}</p>
<p>As, the first term is a constant anyway so to increase the function, is to maximize the second term. The term which we may already know as the cost function. Written as &ndash;
$$J(\theta) = \frac {1}{2} \sum_{i=1}^{n} (y^{(i)}- \theta^Tx^{(i)})^2$$</p>
<p>Now, it feels like cost function was always meant to be the cost function. It didn&rsquo;t just drop from anywhere. And suddenly you find yourself asking your intuition to agree that half of the sum of the squares of the distances of prediction from the actual value, is need to be reduced to get a better parameter, i.e. $\theta$.</p>
<p>If you have come this far, please leave a comment and a reaction. Let me know, if I made any mistake. Thanks!</p>

</div>

  
<footer class='entry-footer'>
  <div class='container sep-before'><div class='tags'><svg class='icon' viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
  
  <path d="M20.59,13.41l-7.17,7.17a2,2,0,0,1-2.83,0L2,12V2H12l8.59,8.59A2,2,0,0,1,20.59,13.41Z"/>
  <line x1="7" y1="7" x2="7" y2="7"/>
  
</svg>
<span class='screen-reader-text'>Tags: </span><a class='tag' href='/tTales/tags/machine-learning/'>Machine Learning</a>, <a class='tag' href='/tTales/tags/probability/'>Probability</a>, <a class='tag' href='/tTales/tags/regression/'>Regression</a></div>

  </div>
</footer>


</article>


<section id='comments' class='comments'>
  <div class='container sep-before'>
    <div class='comments-area'><div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "hans-ollivander" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</div>
  </div>
</section>

      </main>

      <footer id='footer' class='footer'>
        <div class='container sep-before'><section class='widget widget-social_menu sep-after'><nav aria-label='Social Menu'>
    <ul><li>
        <a href='https://github.com/011ivand3r' target='_blank' rel='noopener'>
          <span class='screen-reader-text'>Open Github account in new tab</span><svg class='icon' viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
  
  <path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"/>
  
</svg>
</a>
      </li><li>
        <a href='https://twitter.com/011ivand3r' target='_blank' rel='noopener'>
          <span class='screen-reader-text'>Open Twitter account in new tab</span><svg class='icon' viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
  
  <path d="M23 3a10.9 10.9 0 0 1-3.14 1.53 4.48 4.48 0 0 0-7.86 3v1A10.66 10.66 0 0 1 3 4s-4 9 5 13a11.64 11.64 0 0 1-7 2c9 5 20 0 20-11.5a4.5 4.5 0 0 0-.08-.83A7.72 7.72 0 0 0 23 3z"/>
  
</svg>
</a>
      </li><li>
        <a href='https://instagram.com/011ivand3r' target='_blank' rel='noopener'>
          <span class='screen-reader-text'>Open Instagram account in new tab</span><svg class='icon' viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
  
  <rect x="2" y="2" width="20" height="20" rx="5" ry="5"/>
  <path d="M16 11.37A4 4 0 1 1 12.63 8 4 4 0 0 1 16 11.37z"/>
  <line x1="17.5" y1="6.5" x2="17.5" y2="6.5"/>
  
</svg>
</a>
      </li><li>
        <a href='mailto:han5.011ivand3r@gmail.com' target='_blank' rel='noopener'>
          <span class='screen-reader-text'>Contact via Email</span><svg class='icon' viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
  
  <path d="M4 4h16c1.1 0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1 0-2-.9-2-2V6c0-1.1.9-2 2-2z"/>
  <polyline points="22,6 12,13 2,6"/>
  
</svg>
</a>
      </li><li>
        <a href='https://www.youtube.com/channel/UCaAyf7QcsnIT7jGUaBDzbbw' target='_blank' rel='noopener'>
          <span class='screen-reader-text'>Open Youtube account in new tab</span><svg class='icon' viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
  
  <path d="M22.54 6.42a2.78 2.78 0 0 0-1.94-2C18.88 4 12 4 12 4s-6.88 0-8.6.46a2.78 2.78 0 0 0-1.94 2A29 29 0 0 0 1 11.75a29 29 0 0 0 .46 5.33A2.78 2.78 0 0 0 3.4 19c1.72.46 8.6.46 8.6.46s6.88 0 8.6-.46a2.78 2.78 0 0 0 1.94-2 29 29 0 0 0 .46-5.25 29 29 0 0 0-.46-5.33z" />
  <polygon points="9.75 15.02 15.5 11.75 9.75 8.48 9.75 15.02" />
  
</svg>
</a>
      </li></ul>
  </nav>
</section><div class='copyright'>
  <p> &copy; 2020 han5  011ivand3r </p>
</div>

        </div>
      </footer>

    </div>
  </div><script>window.__assets_js_src="/tTales/assets/js/"</script>

<script src='/tTales/assets/js/main.c3bcf2df.js'></script><script src='/tTales/js/custom.js'></script><script type='text/x-mathjax-config'>
  MathJax.Hub.Config({})
</script>

<script type='text/javascript' async src='//unpkg.com/mathjax@2.7.5/MathJax.js?config=TeX-MML-AM_CHTML'></script>

</body>

</html>

